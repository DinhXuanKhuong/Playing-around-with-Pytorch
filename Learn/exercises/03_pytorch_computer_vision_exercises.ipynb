{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vex99np2wFVt"
      },
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/). \n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA). \n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Apr 16 03:23:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "9c150c50-a092-4f34-9d33-b45247fb080d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1\n"
          ]
        }
      ],
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFX7tc1w-en"
      },
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Transpostation\n",
        "- Medical area\n",
        "- Face ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBK-WI6YxDYa"
      },
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When a machine learning model performs well on its training data but poorly on new, unseen data because it has 'memorized\" the training data, including its noise, instead of learning the general underlying patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeYFEqw8xK26"
      },
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. \n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Drop out \n",
        "- generalization\n",
        "- augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdEEFEqxM-8"
      },
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "outputs": [],
      "source": [
        "# done, i used an orange image, and it gave a 47% of orange and 49% of bell pepper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvf-3pODxXYI"
      },
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SHjeuN81bHza"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:10<00:00, 925kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 99.1kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:03<00:00, 499kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.49MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import pandas as pd\n",
        "from torchvision import datasets\n",
        "import torchvision\n",
        "\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform= torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data  = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ],
      "source": [
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ],
      "source": [
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 5)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZW-uAbxe_F"
      },
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QVFsYi1PbItE"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig  = plt.figure(figsize=(15, 3))\n",
        "for i in range(1, 5+1):\n",
        "    x = random.randint(0, len(train_data))\n",
        "    img, label = train_data[x]\n",
        "    fig.add_subplot(1, 5, i)\n",
        "    plt.title(f'{label}')\n",
        "    plt.imshow(img.squeeze())\n",
        "    plt.axis(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPDzW0wxhi3"
      },
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# iter(train_dataloader)\n",
        "len(train_dataloader), len(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCCVfXk5xjYS"
      },
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_3zUr7xlhy"
      },
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1CsHhPpxp1w"
      },
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQwzqlBWxrpG"
      },
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6bDhoWxt2y"
      },
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHS20cNTxwSi"
      },
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset. \n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been. \n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error? \n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMUsDcN/+FAm9Pf7Ifqs6AZ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
