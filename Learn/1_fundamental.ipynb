{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eb489d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c01cf",
   "metadata": {},
   "source": [
    "#### a tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a8ab7755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(1)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8920e50",
   "metadata": {},
   "source": [
    "#### number of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6939f5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f737e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, int)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item(), type(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "772d4ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([2, 4])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a5c752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db82ca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[2,3], [4,5]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "88bf54b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "12c8385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04c101e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7, 4],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[1, 9],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [8, 8]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[[7, 4], [0, 1]],\n",
    "                     [[1, 9,], [2, 3]],\n",
    "                     [[5, 6], [8, 8]]\n",
    "                     ])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "15bae66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84480db1",
   "metadata": {},
   "source": [
    "Same color to find dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "979a5632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2933, 0.5889, 0.4117, 0.0992],\n",
       "         [0.3078, 0.7786, 0.8016, 0.3649],\n",
       "         [0.6286, 0.9663, 0.7687, 0.4566]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand((3,4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6d37a35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5745, 0.9200, 0.3230],\n",
       "         [0.8613, 0.0919, 0.3102],\n",
       "         [0.9536, 0.6002, 0.0351],\n",
       "         ...,\n",
       "         [0.6501, 0.1374, 0.3852],\n",
       "         [0.7029, 0.0650, 0.1280],\n",
       "         [0.0728, 0.4482, 0.8423]],\n",
       "\n",
       "        [[0.3919, 0.1191, 0.7616],\n",
       "         [0.9423, 0.8760, 0.9324],\n",
       "         [0.3308, 0.0646, 0.4916],\n",
       "         ...,\n",
       "         [0.4601, 0.4145, 0.8877],\n",
       "         [0.7979, 0.1490, 0.8975],\n",
       "         [0.3493, 0.3416, 0.2586]],\n",
       "\n",
       "        [[0.9752, 0.2840, 0.2329],\n",
       "         [0.7765, 0.1522, 0.3084],\n",
       "         [0.0165, 0.2109, 0.1842],\n",
       "         ...,\n",
       "         [0.7706, 0.6538, 0.3952],\n",
       "         [0.1024, 0.6485, 0.3496],\n",
       "         [0.7555, 0.3809, 0.3577]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8716, 0.6351, 0.7019],\n",
       "         [0.3454, 0.4896, 0.8905],\n",
       "         [0.9717, 0.3601, 0.9916],\n",
       "         ...,\n",
       "         [0.7278, 0.2134, 0.2524],\n",
       "         [0.1369, 0.8770, 0.7452],\n",
       "         [0.5307, 0.9066, 0.6534]],\n",
       "\n",
       "        [[0.2118, 0.8450, 0.1104],\n",
       "         [0.3851, 0.9572, 0.7999],\n",
       "         [0.3918, 0.2505, 0.0856],\n",
       "         ...,\n",
       "         [0.8415, 0.9385, 0.7613],\n",
       "         [0.8405, 0.6385, 0.8038],\n",
       "         [0.0070, 0.9709, 0.6002]],\n",
       "\n",
       "        [[0.5102, 0.6497, 0.7146],\n",
       "         [0.2908, 0.6484, 0.3615],\n",
       "         [0.5139, 0.3529, 0.4334],\n",
       "         ...,\n",
       "         [0.4984, 0.0323, 0.8270],\n",
       "         [0.8660, 0.2001, 0.7926],\n",
       "         [0.1140, 0.6855, 0.0086]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3116f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "35a1ed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3cbfc8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(0,10)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "16756695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like = torch.zeros_like(zero_to_ten)\n",
    "like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "05d63a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "51517ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([2.0, 3., 4.], dtype = None, device=None, requires_grad=False)\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "80df19dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 11.], dtype=torch.float16)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([10., 11.], dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b4980",
   "metadata": {},
   "source": [
    "Three most common attributes about a tensor are:\n",
    "- shape\n",
    "- dtype\n",
    "- device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3bf39efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3588, 0.9211, 0.8627, 0.8223],\n",
      "        [0.5248, 0.5881, 0.2746, 0.3791],\n",
      "        [0.2975, 0.6450, 0.0163, 0.9160]])\n",
      "shape:  torch.Size([3, 4])\n",
      "data type:  torch.float32\n",
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "print(some_tensor)\n",
    "print(\"shape: \", some_tensor.shape)\n",
    "print(\"data type: \", some_tensor.dtype)\n",
    "print(\"device: \", some_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "09b18e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "042d3c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9cb70004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor doesn't change if you don't reassign it\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cf733e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8546352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor += 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "71ad4691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e2a4c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cedc3548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original tensor is still unchanged\n",
    "tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1715ff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "equals:  tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# element-wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"equals: \", tensor * tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c05bfd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in python @ is the symbol for matrix multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "02eef313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3b01dc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f9dd11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 852 μs, sys: 0 ns, total: 852 μs\n",
      "Wall time: 538 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "res = 0\n",
    "for val in tensor:\n",
    "    res += val**2\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cda87b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 μs, sys: 8 μs, total: 61 μs\n",
      "Wall time: 63.4 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9377d7",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6ce32147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5888, 0.8403],\n",
       "         [0.4761, 0.7140],\n",
       "         [0.4644, 0.6362]]),\n",
       " tensor([[0.8892, 0.1317],\n",
       "         [0.7164, 0.2706],\n",
       "         [0.6560, 0.6614]]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.rand((3,2))\n",
    "tensor_B = torch.rand((3,2))\n",
    "\n",
    "tensor_A, tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c96d4b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8892, 0.7164, 0.6560],\n",
       "        [0.1317, 0.2706, 0.6614]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8b131377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6342, 0.6491, 0.9419],\n",
       "        [0.5173, 0.5342, 0.7845],\n",
       "        [0.4968, 0.5049, 0.7254]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A @ tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "61898dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6342, 0.6491, 0.9419],\n",
       "        [0.5173, 0.5342, 0.7845],\n",
       "        [0.4968, 0.5049, 0.7254]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "963945c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6342, 0.6491, 0.9419],\n",
       "        [0.5173, 0.5342, 0.7845],\n",
       "        [0.4968, 0.5049, 0.7254]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc8d8a",
   "metadata": {},
   "source": [
    "### Test with Linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e4ec7ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "output: tensor([[ 1.4348, -0.0705,  0.6433,  0.2786],\n",
      "        [ 1.2997, -0.1339,  0.6427,  0.2649],\n",
      "        [ 1.2478, -0.1824,  0.6334,  0.2367]], grad_fn=<AddmmBackward0>)\n",
      " with shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, out_features= 4) # create a layer of 4 units\n",
    "\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"output: {output}\\n with shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4186f",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e17442a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cb2ddbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum: {}\".format(x.min()))\n",
    "print(\"Maximum: {}\".format(x.max()))\n",
    "print(\"Mean: {}\".format(x.type(torch.float32).mean())) # mean() wont work without float datatype\n",
    "print(\"Sum: {}\".format(x.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e7e632",
   "metadata": {},
   "source": [
    "#### Positional min/max\n",
    "You can also find the index of a tensor where the max or minimum occurs with `torch.argmax()` and `torch.argmin()` respectively.\n",
    "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the softmax activation function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "21878c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:  tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index of the max value is: 8\n",
      "Index of the min value is: 0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10, 100, 10)\n",
    "print(\"Tensor: \", tensor)\n",
    "\n",
    "print(f\"Index of the max value is: {tensor.argmax()}\")\n",
    "print(f\"Index of the min value is: {tensor.argmin()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e8f60",
   "metadata": {},
   "source": [
    "#### Change tensor datatype\n",
    "As mentioned, a common issue with deep learning operations is having your tensors in different datatypes.\n",
    "\n",
    "If one tensor is in torch.float64 and another is in torch.float32, you might run into some errors.\n",
    "\n",
    "But there's a fix.\n",
    "\n",
    "You can change the datatypes of tensors using `torch.Tensor.type(dtype=None)` where the dtype parameter is the datatype you'd like to use.\n",
    "\n",
    "First we'll create a tensor and check its datatype (the default is torch.float32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fe4d362e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(10, 100, 10)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0541925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float32 = tensor.type(torch.float32)\n",
    "tensor_float32.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fd81e",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing\n",
    "\n",
    "often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
    "\n",
    "To do so, some popular methods are:\n",
    "\n",
    "|Method |\tOne-line description|\n",
    "|:-----|:---:|\n",
    "|torch.reshape(input, shape) |\tReshapes input to shape (if compatible), can also use torch.Tensor.reshape(). |\n",
    "|Tensor.view(shape) |\tReturns a view of the original tensor in a different shape but shares the same data as the original tensor. |\n",
    "|torch.stack(tensors, dim=0) |\tConcatenates a sequence of tensors along a new dimension (dim), all tensors must be same size. |\n",
    "|torch.squeeze(input) |\tSqueezes input to remove all the dimenions with value 1.|\n",
    "|torch.unsqueeze(input, dim) |\tReturns input with a dimension value of 1 added at dim. |\n",
    "|torch.permute(input, dims) |\tReturns a view of the original input with its dimensions permuted (rearranged) to dims.|\n",
    "\n",
    "Why do any of these?\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "faacdfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(1., 8)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "180a782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "14d76092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped = tensor.reshape(1, 7)\n",
    "tensor_reshaped, tensor_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0db1277c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_C = torch.arange(1., 9)\n",
    "tensor_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "03a95791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tensor_C.view(2, 4)\n",
    "z\n",
    "# Change view (keeps same data as original but changes view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158cda9f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Remember though, changing the view of a tensor with torch.view() really only creates a new view of the same tensor.\n",
    "\n",
    "So changing the view changes the original tensor too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "52323aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.,  2.,  3.,  4.],\n",
       "         [-1.,  6.,  7.,  8.]]),\n",
       " tensor([-1.,  2.,  3.,  4., -1.,  6.,  7.,  8.]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = -1\n",
    "z, tensor_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fb258a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7.],\n",
       "        [1., 2., 3., 4., 5., 6., 7.],\n",
       "        [1., 2., 3., 4., 5., 6., 7.],\n",
       "        [1., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([tensor for i in range(4)], dim = 0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "32bb8095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked[:, 0] = 5\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65352ef4",
   "metadata": {},
   "source": [
    "How about remove all single dimensions from a tensor?\n",
    "\n",
    "To do so you can use `torch.squeeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "770bed61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "previous tensor's shape: torch.Size([1, 7])\n",
      "new tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "new tensor: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"previous tensor: {tensor_reshaped}\")\n",
    "print(f\"previous tensor's shape: {tensor_reshaped.shape}\")\n",
    "\n",
    "x_squeezed = tensor_reshaped.squeeze()\n",
    "\n",
    "print(f\"new tensor: {x_squeezed}\")\n",
    "print(f\"new tensor: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d5b142d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9564a787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stacked_squeezed = x_stacked.squeeze()\n",
    "new_stacked_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f4879c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stacked_squeezed #so that squeeze just remove single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0cac91b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org = torch.rand((224, 224, 3))\n",
    "x_permuted = x_org.permute(2, 0, 1)# shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "x_org.shape, x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a513734d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.6940e-01, 5.6772e-01, 7.4109e-01],\n",
       "         [4.2940e-01, 8.8544e-01, 5.7390e-01],\n",
       "         [2.6658e-01, 6.2745e-01, 2.6963e-01],\n",
       "         ...,\n",
       "         [8.8455e-01, 3.8850e-01, 3.9324e-01],\n",
       "         [4.5545e-02, 4.2129e-01, 8.5366e-01],\n",
       "         [5.6972e-01, 2.0877e-01, 6.5391e-01]],\n",
       "\n",
       "        [[3.3968e-01, 9.5650e-01, 6.6023e-02],\n",
       "         [3.4206e-01, 1.7213e-02, 3.0308e-01],\n",
       "         [6.5762e-01, 9.8131e-01, 5.8397e-01],\n",
       "         ...,\n",
       "         [6.7008e-01, 6.1587e-02, 4.2213e-01],\n",
       "         [4.8892e-01, 2.9742e-01, 6.8196e-01],\n",
       "         [5.3223e-01, 8.5103e-01, 4.5559e-01]],\n",
       "\n",
       "        [[1.8443e-01, 8.5328e-01, 5.6982e-01],\n",
       "         [3.5680e-01, 1.7045e-01, 6.1719e-01],\n",
       "         [2.3124e-02, 6.3169e-01, 7.4722e-01],\n",
       "         ...,\n",
       "         [5.4622e-01, 6.2962e-01, 4.5285e-01],\n",
       "         [8.4301e-01, 2.0853e-01, 6.7919e-01],\n",
       "         [4.9887e-01, 9.3264e-02, 3.0635e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[7.5457e-01, 4.3883e-01, 1.7798e-01],\n",
       "         [9.0903e-04, 2.9150e-01, 8.8188e-01],\n",
       "         [3.5989e-01, 1.9892e-01, 5.7113e-01],\n",
       "         ...,\n",
       "         [2.5104e-01, 6.5680e-01, 2.6024e-01],\n",
       "         [2.5154e-01, 5.8952e-01, 7.9429e-01],\n",
       "         [1.7896e-01, 9.9542e-01, 6.6165e-01]],\n",
       "\n",
       "        [[9.8712e-01, 5.8770e-01, 7.3755e-01],\n",
       "         [1.5513e-01, 7.8808e-01, 3.7591e-01],\n",
       "         [7.4419e-01, 8.6212e-01, 7.5481e-01],\n",
       "         ...,\n",
       "         [5.5916e-01, 9.7749e-01, 6.5402e-01],\n",
       "         [6.1312e-01, 8.2450e-01, 3.7530e-01],\n",
       "         [3.4504e-01, 6.3593e-01, 8.2161e-01]],\n",
       "\n",
       "        [[9.6185e-01, 7.9253e-01, 2.9522e-01],\n",
       "         [6.3930e-01, 7.1579e-01, 6.0992e-01],\n",
       "         [1.3687e-01, 4.3023e-01, 7.2646e-01],\n",
       "         ...,\n",
       "         [7.0843e-01, 3.8476e-02, 6.7473e-01],\n",
       "         [8.6134e-01, 1.2439e-01, 3.5553e-01],\n",
       "         [1.1667e-01, 1.1329e-01, 8.5999e-01]]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d09eb0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.6940e-01, 4.2940e-01, 2.6658e-01,  ..., 8.8455e-01,\n",
       "          4.5545e-02, 5.6972e-01],\n",
       "         [3.3968e-01, 3.4206e-01, 6.5762e-01,  ..., 6.7008e-01,\n",
       "          4.8892e-01, 5.3223e-01],\n",
       "         [1.8443e-01, 3.5680e-01, 2.3124e-02,  ..., 5.4622e-01,\n",
       "          8.4301e-01, 4.9887e-01],\n",
       "         ...,\n",
       "         [7.5457e-01, 9.0903e-04, 3.5989e-01,  ..., 2.5104e-01,\n",
       "          2.5154e-01, 1.7896e-01],\n",
       "         [9.8712e-01, 1.5513e-01, 7.4419e-01,  ..., 5.5916e-01,\n",
       "          6.1312e-01, 3.4504e-01],\n",
       "         [9.6185e-01, 6.3930e-01, 1.3687e-01,  ..., 7.0843e-01,\n",
       "          8.6134e-01, 1.1667e-01]],\n",
       "\n",
       "        [[5.6772e-01, 8.8544e-01, 6.2745e-01,  ..., 3.8850e-01,\n",
       "          4.2129e-01, 2.0877e-01],\n",
       "         [9.5650e-01, 1.7213e-02, 9.8131e-01,  ..., 6.1587e-02,\n",
       "          2.9742e-01, 8.5103e-01],\n",
       "         [8.5328e-01, 1.7045e-01, 6.3169e-01,  ..., 6.2962e-01,\n",
       "          2.0853e-01, 9.3264e-02],\n",
       "         ...,\n",
       "         [4.3883e-01, 2.9150e-01, 1.9892e-01,  ..., 6.5680e-01,\n",
       "          5.8952e-01, 9.9542e-01],\n",
       "         [5.8770e-01, 7.8808e-01, 8.6212e-01,  ..., 9.7749e-01,\n",
       "          8.2450e-01, 6.3593e-01],\n",
       "         [7.9253e-01, 7.1579e-01, 4.3023e-01,  ..., 3.8476e-02,\n",
       "          1.2439e-01, 1.1329e-01]],\n",
       "\n",
       "        [[7.4109e-01, 5.7390e-01, 2.6963e-01,  ..., 3.9324e-01,\n",
       "          8.5366e-01, 6.5391e-01],\n",
       "         [6.6023e-02, 3.0308e-01, 5.8397e-01,  ..., 4.2213e-01,\n",
       "          6.8196e-01, 4.5559e-01],\n",
       "         [5.6982e-01, 6.1719e-01, 7.4722e-01,  ..., 4.5285e-01,\n",
       "          6.7919e-01, 3.0635e-01],\n",
       "         ...,\n",
       "         [1.7798e-01, 8.8188e-01, 5.7113e-01,  ..., 2.6024e-01,\n",
       "          7.9429e-01, 6.6165e-01],\n",
       "         [7.3755e-01, 3.7591e-01, 7.5481e-01,  ..., 6.5402e-01,\n",
       "          3.7530e-01, 8.2161e-01],\n",
       "         [2.9522e-01, 6.0992e-01, 7.2646e-01,  ..., 6.7473e-01,\n",
       "          3.5553e-01, 8.5999e-01]]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_permuted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1856a2b",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7960ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b6596305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cfe1ce",
   "metadata": {},
   "source": [
    "You can also use `:` to specify \"all values in this dimension\" and then use a comma (,) to add another dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1c70bcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "22509b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d3b569b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2bac5d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7d627f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2c890",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c735e",
   "metadata": {},
   "source": [
    "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
    "\n",
    "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
    "\n",
    "    torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.\n",
    "    torch.Tensor.numpy() - PyTorch tensor -> NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8f14ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "be867be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1., 8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a0815",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    Note: By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
    "\n",
    "    However, many PyTorch calculations default to using float32.\n",
    "\n",
    "    So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use tensor = torch.from_numpy(array).type(torch.float32).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fcbbab0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.type(torch.float32)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1ee46f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we reassigned the tensor above, if you change the tensor, the darray stays the same\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b06f4aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensor to numpy\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d0c77cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5aa879d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "index of max value: 8\n",
      "index of min value: 0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10, 100, 10)\n",
    "print(tensor)\n",
    "\n",
    "print(f\"index of max value: {tensor.argmax()}\")\n",
    "print(f'index of min value: {tensor.argmin()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c598fd4e",
   "metadata": {},
   "source": [
    "### Reproducibility (trying to take the random out of random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1483eeb",
   "metadata": {},
   "source": [
    "What if we want to create two tensors with same values randomely?\n",
    "\n",
    "As in, the tensors would still contain random values but they would be of the same flavour.\n",
    "\n",
    "That's where `torch.manual_seed(seed)` comes in, where seed is an integer (like 42 but it could be anything) that flavours the randomness.\n",
    "\n",
    "Let's try it out by creating some more flavoured random tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "eb6039d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2249, 0.7745, 0.5017, 0.3579],\n",
      "        [0.6479, 0.1607, 0.3716, 0.3174],\n",
      "        [0.2452, 0.6733, 0.5015, 0.1196]])\n",
      "tensor([[0.2249, 0.7745, 0.5017, 0.3579],\n",
      "        [0.6479, 0.1607, 0.3716, 0.3174],\n",
      "        [0.2452, 0.6733, 0.5015, 0.1196]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 2005\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_C = torch.rand((3, 4))\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_D = torch.rand((3, 4))\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "random_tensor_D == random_tensor_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6fbc3a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a900960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
